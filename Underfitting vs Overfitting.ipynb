{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "presidential-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "amazing-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./home-data-for-ml-course/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "naked-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X with required feautres\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = data[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "atmospheric-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create y (target variable)\n",
    "y = data.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "improving-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_X, val_X, train_y, val_y = train_test_split(X,y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "novel-thinking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = DecisionTreeRegressor(random_state=1)\n",
    "# Fit the model\n",
    "model.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "enhanced-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using validation data\n",
    "val_predictions = model.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "exciting-resistance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Successful Predicitons: 1\n"
     ]
    }
   ],
   "source": [
    "# Compare Predicitons made from validation data and Actual values in validation data\n",
    "print(f'Count of Successful Predicitons: {sum(val_predictions == val_y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "democratic-wealth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error Value: 29653\n"
     ]
    }
   ],
   "source": [
    "# Check Mean Absolute Error\n",
    "mae_value = mean_absolute_error(val_predictions, val_y)\n",
    "print(f'Mean Absolute Error Value: {mae_value:.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-local",
   "metadata": {},
   "source": [
    "Now, we'll try using different number of leaf nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dated-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Function to calculate Mean Absolute Error for a given leaf nodes value\n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes = max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    val_predictions = model.predict(val_X)\n",
    "    mae_value = mean_absolute_error(val_predictions, val_y)\n",
    "#     print(f'MAE value using {max_leaf_nodes} leaf nodes: {mae_value:.0f}')\n",
    "    return mae_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "extreme-township",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_nodes = [5,25,50,100,250,500]\n",
    "val = []\n",
    "for i in leaf_nodes:\n",
    "    val.append(int(get_mae(i,train_X, val_X, train_y, val_y)))\n",
    "# Find the best tree size for better modelling\n",
    "best_tree_size = leaf_nodes[val.index(min(val))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "injured-buddy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_leaf_nodes=100, random_state=0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model using optimal tree size\n",
    "optimised_model = DecisionTreeRegressor(max_leaf_nodes = best_tree_size, random_state =0)\n",
    "\n",
    "# Fit the model using all the data\n",
    "optimised_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "sunrise-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the predictions using optimised model\n",
    "val_predictions = optimised_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "peripheral-inspector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare predicted values with actual values\n",
    "sum(val_predictions==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "traditional-digest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimised Mean Absolute Error: 16629\n"
     ]
    }
   ],
   "source": [
    "# Check the Mean Absolute Error\n",
    "op_mae_value = mean_absolute_error(val_predictions,y)\n",
    "print(f'Optimised Mean Absolute Error: {op_mae_value:.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-congo",
   "metadata": {},
   "source": [
    "We've tuned this model and improved results. But we are still using Decision Tree models, which are not very sophisticated by modern machine learning standards. In the next step we will learn to use Random Forests to improve our models even more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
